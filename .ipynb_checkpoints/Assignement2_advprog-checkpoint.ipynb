{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91de30f1-8351-4324-b775-b09c03d79000",
   "metadata": {},
   "source": [
    "# 1. Simplified EDA :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c6cea1e-ae0d-4be5-aa8a-d1c0b74cec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2940 entries, 0 to 2939\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   hrs                      2940 non-null   float64\n",
      " 1   absences                 2940 non-null   float64\n",
      " 2   JobInvolvement           2940 non-null   float64\n",
      " 3   PerformanceRating        2940 non-null   float64\n",
      " 4   EnvironmentSatisfaction  2940 non-null   float64\n",
      " 5   JobSatisfaction          2940 non-null   float64\n",
      " 6   WorkLifeBalance          2940 non-null   float64\n",
      " 7   Age                      2940 non-null   float64\n",
      " 8   BusinessTravel           2940 non-null   object \n",
      " 9   Department               2940 non-null   object \n",
      " 10  DistanceFromHome         2940 non-null   float64\n",
      " 11  Education                2940 non-null   float64\n",
      " 12  EducationField           2940 non-null   object \n",
      " 13  EmployeeCount            2940 non-null   float64\n",
      " 14  EmployeeID               2940 non-null   float64\n",
      " 15  Gender                   2940 non-null   object \n",
      " 16  JobLevel                 2940 non-null   float64\n",
      " 17  JobRole                  2940 non-null   object \n",
      " 18  MaritalStatus            2940 non-null   object \n",
      " 19  MonthlyIncome            2940 non-null   float64\n",
      " 20  NumCompaniesWorked       2940 non-null   float64\n",
      " 21  Over18                   2940 non-null   object \n",
      " 22  PercentSalaryHike        2940 non-null   float64\n",
      " 23  StandardHours            2940 non-null   float64\n",
      " 24  StockOptionLevel         2940 non-null   float64\n",
      " 25  TotalWorkingYears        2940 non-null   float64\n",
      " 26  TrainingTimesLastYear    2940 non-null   float64\n",
      " 27  YearsAtCompany           2940 non-null   float64\n",
      " 28  YearsSinceLastPromotion  2940 non-null   float64\n",
      " 29  YearsWithCurrManager     2940 non-null   float64\n",
      " 30  Attrition                2940 non-null   object \n",
      "dtypes: float64(23), object(8)\n",
      "memory usage: 712.2+ KB\n",
      "None\n",
      "         hrs  absences  JobInvolvement  PerformanceRating  \\\n",
      "0   6.420398      19.0             4.0                3.0   \n",
      "1   7.615521       7.0             4.0                3.0   \n",
      "2   6.093781      18.0             3.0                3.0   \n",
      "3   6.460209       5.0             4.0                3.0   \n",
      "4  10.384712       2.0             2.0                3.0   \n",
      "\n",
      "   EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance   Age  \\\n",
      "0                      2.0              2.0              3.0  28.0   \n",
      "1                      4.0              2.0              3.0  28.0   \n",
      "2                      1.0              3.0              4.0  37.0   \n",
      "3                      3.0              4.0              3.0  32.0   \n",
      "4                      4.0              2.0              4.0  21.0   \n",
      "\n",
      "  BusinessTravel              Department  ...  Over18  PercentSalaryHike  \\\n",
      "0  Travel_Rarely  Research & Development  ...       Y               18.0   \n",
      "1  Travel_Rarely  Research & Development  ...       Y               15.0   \n",
      "2  Travel_Rarely  Research & Development  ...       Y               17.0   \n",
      "3     Non-Travel  Research & Development  ...       Y               17.0   \n",
      "4  Travel_Rarely  Research & Development  ...       Y               11.0   \n",
      "\n",
      "  StandardHours  StockOptionLevel  TotalWorkingYears TrainingTimesLastYear  \\\n",
      "0           8.0               1.0                1.0                   2.0   \n",
      "1           8.0               0.0                1.0                   1.0   \n",
      "2           8.0               3.0               16.0                   3.0   \n",
      "3           8.0               1.0                9.0                   5.0   \n",
      "4           8.0               1.0                2.0                   3.0   \n",
      "\n",
      "   YearsAtCompany YearsSinceLastPromotion YearsWithCurrManager  Attrition  \n",
      "0             1.0                     0.0                  0.0         No  \n",
      "1             1.0                     0.0                  0.0         No  \n",
      "2             5.0                     0.0                  2.0         No  \n",
      "3             5.0                     1.0                  2.0         No  \n",
      "4             2.0                     2.0                  2.0         No  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"attrition_availabledata_04.csv\")\n",
    "\n",
    "# Display the structure of the dataset\n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3275a6c9-04c0-4b7d-8fc7-833188bd4912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (2940, 31)\n",
      "Data Types:\n",
      " float64    23\n",
      "object      8\n",
      "Name: count, dtype: int64\n",
      "Missing Values:\n",
      " hrs                        0\n",
      "absences                   0\n",
      "JobInvolvement             0\n",
      "PerformanceRating          0\n",
      "EnvironmentSatisfaction    0\n",
      "JobSatisfaction            0\n",
      "WorkLifeBalance            0\n",
      "Age                        0\n",
      "BusinessTravel             0\n",
      "Department                 0\n",
      "DistanceFromHome           0\n",
      "Education                  0\n",
      "EducationField             0\n",
      "EmployeeCount              0\n",
      "EmployeeID                 0\n",
      "Gender                     0\n",
      "JobLevel                   0\n",
      "JobRole                    0\n",
      "MaritalStatus              0\n",
      "MonthlyIncome              0\n",
      "NumCompaniesWorked         0\n",
      "Over18                     0\n",
      "PercentSalaryHike          0\n",
      "StandardHours              0\n",
      "StockOptionLevel           0\n",
      "TotalWorkingYears          0\n",
      "TrainingTimesLastYear      0\n",
      "YearsAtCompany             0\n",
      "YearsSinceLastPromotion    0\n",
      "YearsWithCurrManager       0\n",
      "Attrition                  0\n",
      "dtype: int64\n",
      "Constant Columns: ['EmployeeCount', 'Over18', 'StandardHours']\n",
      "Attrition Class Distribution:\n",
      " Attrition\n",
      "No     83.877551\n",
      "Yes    16.122449\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Basic information about the data\n",
    "print(\"Shape of the dataset:\", data.shape)\n",
    "print(\"Data Types:\\n\", data.dtypes.value_counts())\n",
    "print(\"Missing Values:\\n\", data.isnull().sum())\n",
    "\n",
    "# Identify constant columns\n",
    "constant_cols = [col for col in data.columns if data[col].nunique() == 1]\n",
    "print(\"Constant Columns:\", constant_cols)\n",
    "\n",
    "# Check the target variable distribution\n",
    "attrition_dist = data[\"Attrition\"].value_counts(normalize=True) * 100\n",
    "print(\"Attrition Class Distribution:\\n\", attrition_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bfa4083-739b-49c9-a2f8-912081933301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop constant columns\n",
    "data_cleaned = data.drop(columns=[\"EmployeeCount\", \"Over18\", \"StandardHours\"])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data_cleaned.drop(columns=[\"Attrition\"])\n",
    "y = data_cleaned[\"Attrition\"].map({\"Yes\": 1, \"No\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907f526-bd92-4c1b-968f-36b5d82f8d19",
   "metadata": {},
   "source": [
    "Through our data summary, we notice that it contains `2940` instances and `31` features and no missing values in all 31 columns.\n",
    "## 1.1 Data type\n",
    "### Numerical variables :\n",
    "We have overall 23 numerical variables, which are :\n",
    "- `hrs`\n",
    "- `absences`\n",
    "- `JobInvolvement`\n",
    "- `PerformanceRating`\n",
    "- `EnvironmentSatisfaction`\n",
    "- `JobSatisfaction`\n",
    "- `WorkLifeBalance`\n",
    "- `Age`\n",
    "- `DistanceFromHome`\n",
    "- `Education`\n",
    "- `EmployeeCount` \n",
    "- `EmployeeID` \n",
    "- `JobLevel`\n",
    "- `MonthlyIncome`\n",
    "- `NumCompaniesWorked`\n",
    "- `PercentSalaryHike`\n",
    "- `StandardHours` \n",
    "- `StockOptionLevel`\n",
    "- `TotalWorkingYears`\n",
    "- `TrainingTimesLastYear`\n",
    "- `YearsAtCompany`\n",
    "- `YearsSinceLastPromotion`\n",
    "- `YearsWithCurrManager`\n",
    "### Categorical variables :\n",
    "There are 8 categories in our data, that can be grouped according to the question :\n",
    "- `BusinessTravel`\n",
    "- `Department`\n",
    "- `EducationField`\n",
    "- `Gender`\n",
    "- `JobRole`\n",
    "- `MaritalStatus`\n",
    "- `Over18`\n",
    "- `Attrition` \n",
    "\n",
    "## 1.2 Categorical variables with high cardinality :\n",
    "2 variables have relatively large number of unique categories, which would make modeling more complex :\n",
    "- `JobRole` : has 9 categories\n",
    "- `EducationField` has 6 categories\n",
    "\n",
    "## 1.3 Features with missing values :\n",
    "None\n",
    "\n",
    "## 1.4 Constant columns or ID columns :\n",
    "### Constant columns :\n",
    "3 constant columns with one value and could be removed from our data :\n",
    "- `Over18` \n",
    "- `EmployeeCount`\n",
    "- `StandardHours`\n",
    "### ID columns :\n",
    "- `EmployeeID` : is a unique identifier and should be removed and excluded from modeling as it doesn't help in predicting the target.\n",
    "\n",
    "## 1.5 Problem type and imbalance :\n",
    "It is a classification problem, where `Attrition` is our target variable. It is likely imbalanced, since we have `83.88%` \"No\" and `16.12%` \"Yes\" in our response variable.\n",
    "\n",
    "## 1.6 Additional considerations :\n",
    "- High cardinality variables should be handled, as they may lead to overfitting if not handled properly.\n",
    "- we have redundancy in our data; constant columns are dropped to reduce noise in the data\n",
    "- We most likely need to resample or class weight adjust our response variable, in order to manage the imbalance in our target. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa08a74-afd6-4eb2-b0c3-5c2caf141276",
   "metadata": {},
   "source": [
    "# 2. Data setup :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c3a79-0800-4283-b6dc-5e96c0ad5db0",
   "metadata": {},
   "source": [
    "## 2.1 Data split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4be49253-1db7-4f12-bf20-011be41908f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2352, 27)\n",
      "Test set shape: (588, 27)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f5e4b-8cd4-43ef-9d15-4b986d6d5db7",
   "metadata": {},
   "source": [
    "## 2.2 Step for inner evaluation :\n",
    "\n",
    "- For inner evaluation, we'd use `3-fold-cross-validation` for computational efficiency. It would allow us to divide the training set into 3 folds; 2 for training and third for validation in each iteration\n",
    "- As for the workflow, we'd apply the method across all models and hyperparameter tuning tasks for consistency\n",
    "- We'd then go for cross validation to reduce the risk of overfitting\n",
    "- Finally, we'd choose a metric suited for the problem. We would choose F1-score metric, since we have an imbalanced dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0f2de-af2a-42ed-8ad4-694ebbe6f335",
   "metadata": {},
   "source": [
    "# 3. BASIC METHODS: TREES AND KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8da6a8-4d74-4a12-b53f-08bf7a311c86",
   "metadata": {},
   "source": [
    "## 3.1 rain, Evaluate, and Compare Two Basic Methods with Default Hyperparameters\n",
    "- We'd compare two basic methods (Decision tree and KNN) with default hyperparameters alongside `DummyClassifier`\n",
    "- For KNN, we'd compare two scaling methods (StandardScaling vs MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0351a799-e86c-464b-a1d3-e89035693dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Results:\n",
      "           Scaler          Model  Accuracy  Balanced Accuracy  \\\n",
      "0  StandardScaler  Decision Tree  0.935374           0.880730   \n",
      "1  StandardScaler            KNN  0.863946           0.651180   \n",
      "2  StandardScaler          Dummy  0.838435           0.500000   \n",
      "3    MinMaxScaler  Decision Tree  0.935374           0.880730   \n",
      "4    MinMaxScaler            KNN  0.826531           0.590627   \n",
      "5    MinMaxScaler          Dummy  0.838435           0.500000   \n",
      "\n",
      "   Training Time (s)  \n",
      "0           0.042549  \n",
      "1           0.007462  \n",
      "2           0.007779  \n",
      "3           0.030499  \n",
      "4           0.006964  \n",
      "5           0.006824  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Preprocessing\n",
    "categorical_cols = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = X_train.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "# Define preprocessors\n",
    "scalers = {\n",
    "    \"StandardScaler\": StandardScaler(),\n",
    "    \"MinMaxScaler\": MinMaxScaler()\n",
    "}\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Dummy\": DummyClassifier(strategy=\"most_frequent\"),\n",
    "}\n",
    "\n",
    "# Baseline evaluation with default hyperparameters\n",
    "results = []\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    for model_name, model in models.items():\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", scaler, numerical_cols),\n",
    "                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "            ]\n",
    "        )\n",
    "        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "        \n",
    "        # Measure training time\n",
    "        start_time = time.time()\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Save results\n",
    "        results.append({\n",
    "            \"Scaler\": scaler_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Balanced Accuracy\": bal_acc,\n",
    "            \"Training Time (s)\": training_time,\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Baseline Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0170e7ed-2c73-4bba-8e5c-e5ba125e2c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for KNN: {'model__n_neighbors': 3}\n",
      "Best Parameters for Decision Tree: {'model__max_depth': None}\n",
      "Best Balanced Accuracy (KNN): 0.6600106080687257\n",
      "Best Balanced Accuracy (Decision Tree): 0.7737843581511896\n",
      "Final KNN Test Accuracy: 0.7608839543076759\n",
      "Final Decision Tree Test Accuracy: 0.8807302231237323\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning (HPO)\n",
    "param_grid_knn = {\"model__n_neighbors\": [3, 5, 7, 9]}\n",
    "param_grid_tree = {\"model__max_depth\": [3, 5, 10, None]}\n",
    "\n",
    "# GridSearchCV for KNN\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "    ]\n",
    ")\n",
    "knn_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", KNeighborsClassifier())])\n",
    "grid_knn = GridSearchCV(knn_pipeline, param_grid_knn, cv=3, scoring=\"balanced_accuracy\", n_jobs=-1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV for Decision Tree\n",
    "tree_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", DecisionTreeClassifier(random_state=42))])\n",
    "grid_tree = GridSearchCV(tree_pipeline, param_grid_tree, cv=3, scoring=\"balanced_accuracy\", n_jobs=-1)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "# Compare HPO results\n",
    "print(\"Best Parameters for KNN:\", grid_knn.best_params_)\n",
    "print(\"Best Parameters for Decision Tree:\", grid_tree.best_params_)\n",
    "print(\"Best Balanced Accuracy (KNN):\", grid_knn.best_score_)\n",
    "print(\"Best Balanced Accuracy (Decision Tree):\", grid_tree.best_score_)\n",
    "\n",
    "# Evaluate the best models on the test set\n",
    "final_knn = grid_knn.best_estimator_\n",
    "final_tree = grid_tree.best_estimator_\n",
    "\n",
    "knn_test_acc = balanced_accuracy_score(y_test, final_knn.predict(X_test))\n",
    "tree_test_acc = balanced_accuracy_score(y_test, final_tree.predict(X_test))\n",
    "\n",
    "print(\"Final KNN Test Accuracy:\", knn_test_acc)\n",
    "print(\"Final Decision Tree Test Accuracy:\", tree_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6a6fa-4f07-4818-ad8b-6b0bc3983d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
